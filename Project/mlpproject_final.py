# -*- coding: utf-8 -*-
"""MLPProject Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qfknuqurOXnSC2CLI3BXDbuDGkI6Vu4L

# Get the data
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('/content/train.csv')
X = data.drop('target', axis = 1)
y = data['target']

"""# Convert the 'last contact date' column to 3 seperate columns"""

X['last contact date'] = pd.to_datetime(X['last contact date'])

X['Month'] = X['last contact date'].dt.month
X['Date'] = X['last contact date'].dt.day
X['Year'] = X['last contact date'].dt.year

X = X.drop('last contact date', axis = 1)

X['Month'] = X['Month'].astype('object')
X['Date'] = X['Date'].astype('object')
X['Year'] = X['Year'].astype('object')

"""# Split the data"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)

X_train

X_test

"""# Preprocess the data (Impute the missing values, encode the categorical features and scale the numerical features)"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer

categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome', 'Month', 'Date', 'Year']
numeric_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']

categorical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(sparse_output=False))
])

numeric_pipeline = Pipeline([
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer(
    transformers=
                  [
                      ('cat', categorical_pipeline, categorical_features),
                      ('num', numeric_pipeline, numeric_features)
                  ],
    remainder='passthrough'  # Keep any extra columns as is
)

X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

X_train = pd.DataFrame(X_train_transformed)
X_test = pd.DataFrame(X_test_transformed)

X_train

X_test

"""# Encode the labels"""

from sklearn.preprocessing import LabelBinarizer
lb = LabelBinarizer()

y_train = lb.fit_transform(y_train)
y_train = pd.DataFrame(y_train, columns=['target'])

y_test = lb.fit_transform(y_test)
y_test = pd.DataFrame(y_test, columns=['target'])

y_train.value_counts()

"""#1. Ridge Classifier - 0.6254"""

import matplotlib.pyplot as plt
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import roc_curve, auc, f1_score
from sklearn.model_selection import train_test_split

# Assuming X_train, X_test, y_train, and y_test are already defined
# Train the RidgeClassifier model
ridge_classifier = RidgeClassifier(alpha=0.1, solver='lsqr', fit_intercept=True)
ridge_classifier.fit(X_train, y_train)

# Get predicted probabilities (decision function scores for each class)
y_scores = ridge_classifier.decision_function(X_test)

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_scores)

# Calculate AUC
roc_auc = auc(fpr, tpr)

# Print AUC
print(f'AUC: {roc_auc:.2f}')

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Calculate F1 score
y_pred = ridge_classifier.predict(X_test)
f1 = f1_score(y_test, y_pred, average='macro')
print(f'F1 Score: {f1}')

from sklearn.metrics import roc_curve, auc

"""#2. Perceptron - 0.7216"""

from sklearn.linear_model import Perceptron
from sklearn.metrics import f1_score

perceptron_classifier = Perceptron()
perceptron_classifier.fit(X_train, y_train)

y_pred = perceptron_classifier.predict(X_test)

f1 = f1_score(y_test, y_pred, average = 'macro')
print(f'F1 Score: {f1}')

"""#3. Logistic Regression - 0.7249"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score

logit_classifier = LogisticRegression(penalty=None, solver = 'newton-cg', class_weight = 'balanced')
logit_classifier.fit(X_train, y_train)

y_pred = logit_classifier.predict(X_test)

f1 = f1_score(y_test, y_pred, average = 'macro')
print(f"F1 Score: {f1}")

"""#4. SGDClassifier - 0.64436

"""

from sklearn.linear_model import SGDClassifier
from sklearn.metrics import f1_score
SGD_classifier = SGDClassifier(loss = 'log_loss')
SGD_classifier.fit(X_train, y_train)
y_pred = SGD_classifier.predict(X_test)
f1 = f1_score(y_test, y_pred, average = 'macro')
print(f"F1 Score : {f1}")

"""#5. Naive Bayes - 0.6948"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import f1_score
gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred = gnb.predict(X_test)
f1 = f1_score(y_test, y_pred, average = 'macro')
print(f"F1 Score: {f1}")

"""#6. K - Nearest Neighbors - 0.6579"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score
knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance', algorithm = 'auto')
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
f1 = f1_score(y_test, y_pred, average = 'macro')
print(f"F1 Score: {f1}")

"""#7. Support Vector Machines with randomized search cv - 0.7562"""

from sklearn.model_selection import RandomizedSearchCV, cross_val_score
from sklearn.svm import SVC
from sklearn.metrics import f1_score

# SVM with hyperparameter tuning
param_dist = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.1, 0.01],
    'kernel': ['linear', 'rbf', 'poly']
}

svc = SVC(class_weight='balanced', random_state=42)
svc_tuned = RandomizedSearchCV(svc, param_distributions=param_dist, scoring='f1_macro', cv=3, n_iter=10, random_state=42, n_jobs=-1)
svc_tuned.fit(X_train, y_train)

# Train the best SVM model
best_svc = svc_tuned.best_estimator_
y_pred_svc = best_svc.predict(X_test)
f1_svc = f1_score(y_test, y_pred_svc, average='macro')


# Results
print(f"Best SVM Params: {svc_tuned.best_params_}")
print(f"SVM F1 Score: {f1_svc:.4f}")

"""#8. Decision Trees - 0.6859"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred = dt.predict(X_test)
f1 = f1_score(y_test, y_pred, average='macro')
print(f"F1 Score: {f1}")

"""#9. Bagging Methods - 0.7712"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import f1_score

# Define the parameter grid for RandomizedSearchCV
param_dist = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2', None],
    'bootstrap': [True, False]
}

# Initialize RandomForestClassifier
rf = RandomForestClassifier(random_state=42, class_weight='balanced')

# Initialize RandomizedSearchCV
rf_random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=20,  # Number of combinations to try
    scoring='f1_macro',  # Optimize for F1 score (macro)
    cv=3,  # 3-fold cross-validation
    verbose=1,
    random_state=42,
    n_jobs=-1  # Use all available CPU cores
)

# Fit the RandomizedSearchCV on training data
rf_random_search.fit(X_train, y_train)

# Get the best model from RandomizedSearchCV
best_rf = rf_random_search.best_estimator_

# Predict on the test data
y_pred = best_rf.predict(X_test)

from sklearn.metrics import f1_score
f1 = f1_score(y_test, y_pred, average = 'macro')
print(f"F1 Score: {f1}")

y_train

"""#10. Boosting Methods - 0.7619"""

from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import f1_score

# Compute scale_pos_weight based on class imbalance
pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]

# Define the parameter grid for RandomizedSearchCV
param_dist = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [3, 6, 10, 15],
    'learning_rate': [0.01, 0.1, 0.2, 0.3],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2, 0.5],
    'reg_alpha': [0, 0.1, 1],
    'reg_lambda': [1, 1.5, 2],
    'scale_pos_weight': [1, pos_weight, 2 * pos_weight]  # Include scale_pos_weight in hyperparameter search
}

# Initialize XGBClassifier
xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')

# Initialize RandomizedSearchCV
xgb_random_search = RandomizedSearchCV(
    estimator=xgb,
    param_distributions=param_dist,
    n_iter=20,
    scoring='f1_macro',
    cv=3,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

# Fit the RandomizedSearchCV on training data
xgb_random_search.fit(X_train, y_train)

# Get the best model from RandomizedSearchCV
best_xgb = xgb_random_search.best_estimator_

# Predict on the test data
y_pred = best_xgb.predict(X_test)

# Evaluate F1 score
f1 = f1_score(y_test, y_pred, average='macro')

# Print results
print(f"Best Hyperparameters: {xgb_random_search.best_params_}")
print(f"F1 Score on Test Data: {f1:.4f}")

"""# 11. Multilayer Perceptron with randomizedsearchcv - 0.7334"""

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import f1_score

# Define the parameter grid
param_distributions = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],
    'activation': ['identity', 'logistic', 'tanh', 'relu'],
    'solver': ['adam', 'sgd'],
    'learning_rate_init': [0.001, 0.01, 0.1],
    'max_iter': [200, 500, 1000],
}

# Initialize the model
mlp = MLPClassifier(random_state=42)

# Randomized search
random_search = RandomizedSearchCV(
    estimator=mlp,
    param_distributions=param_distributions,
    scoring='f1_macro',
    n_iter=20,  # Number of combinations to try
    cv=3,       # Cross-validation splits
    random_state=42,
    n_jobs=-1   # Use all processors
)

# Fit randomized search
random_search.fit(X_train, y_train)

# Predict using the best estimator
best_mlp = random_search.best_estimator_
y_pred = best_mlp.predict(X_test)

# Calculate the F1 score
f1 = f1_score(y_test, y_pred, average='macro')
print(f"Improved F1 Score: {f1}")

import matplotlib.pyplot as plt

models = ['Ridge Classifier', 'SGDClassifier', 'K - Nearest Neighbors', 'Decision Trees',
          'Naive Bayes', 'Perceptron', 'Logistic Regression', 'Multilayer Perceptron',
          'SVM with randomizedsearchcv', 'Boosting Methods', 'Bagging Methods']

f1_scores = [0.6254, 0.64436, 0.6579, 0.6859, 0.6948, 0.7216, 0.7249, 0.7334, 0.7562, 0.7619, 0.7712]

plt.figure(figsize=(10, 6))
plt.barh(models, f1_scores, color='skyblue')
plt.xlabel('F1 Score')
plt.title('F1 Scores of Different Models')

# Display the plot
plt.show()